\documentclass[twocolumn,prl,aps,superscriptaddress]{revtex4-2}

\usepackage{amsmath,amssymb,bm}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{microtype}

\hypersetup{
  colorlinks=true,
  linkcolor=blue!60!black,
  citecolor=blue!60!black,
  urlcolor=blue!60!black,
  pdftitle={Dense Associative Memory on S1: Phase-Gate Computing and Superlinear Capacity in Circular Oscillator Networks},
  pdfauthor={Krzysztof Gwozdz},
  pdfsubject={Associative Memory, Phase Oscillators, Reservoir Computing, Neural Networks},
  pdfkeywords={associative memory, phase oscillators, Kuramoto, dense Hopfield, attention, Turing completeness, reservoir computing}
}

\begin{document}

\title{Dense Associative Memory on $S^1$:\\
Phase-Gate Computing and Superlinear Capacity\\
in Circular Oscillator Networks}

\author{Krzysztof Gwó\'zd\'z}
\affiliation{Independent Researcher}
\email{krisss0@mecom.pl}

\date{\today}

\begin{abstract}
We present the first formal Dense Associative Memory (DAM) framework on
the unit circle $S^1$, where each neuron carries a phase
$\varphi_i \in [0, 2\pi)$ rather than a binary spin.
Unlike prior rotor and complex-valued Hopfield models \cite{aoyagi1995,tanaka1998},
our construction couples a 200\,Hz anchor term that breaks rotational symmetry
and enables injection-locking logic gates---features absent from all previous work.
The energy function
$E(\bm{\varphi}) = -\sum_\mu F\!\left(\sum_i \cos(\varphi_i - \xi_i^\mu)\right)$
generalizes the Krotov-Hopfield Dense Associative Memory
\cite{krotov2020} from $\{{\pm}1\}^N$ to $S^{1N}$.
We prove fixed-point stability analytically and demonstrate empirically that
the exponential interaction $F(m) = e^m$ achieves storage capacity
$\alpha^* = P^*/N = 1.0$ at $N \in \{32, 64, 128\}$
(consistent with exponential capacity theory \cite{ramsauer2020})---a
\textbf{7.2-fold} improvement above the classical Hopfield limit
($\alpha^* \approx 0.138$).
Unlike polynomial interactions, $F=\exp$ is numerically stable at any $N$
due to implicit softmax normalization in the one-step update rule.
The update rule for $F(m) = e^m$ is formally equivalent to Transformer
self-attention \cite{vaswani2017} with circular inner products
(extending Ramsauer et al.\ \cite{ramsauer2020} to circular geometry),
establishing a bridge between physical oscillator dynamics and modern
attention mechanisms.
We demonstrate statistically robust operation across 20 random seeds with Wilson 95\% confidence intervals, achieving 100\% pass rate on the CNOT gate at noise amplitudes up to $a=1.0$.
The same phase-coherent dynamics implement universal Boolean gates
(NOT, AND, XOR, OR, NAND, NOR) at 100\% accuracy, and a cascaded
half-adder, demonstrating computational universality
(functional completeness in the Boolean sense; Turing completeness under
standard unbounded-memory assumptions)
via injection-locking dynamics---a result with no precedent in the
Hopfield or Kuramoto literature.
The physical substrate is an array of 200\,Hz-anchored phase oscillators
governed by injection-locking ordinary differential equations,
directly realizable in CMOS, optical, or neuromorphic hardware.
\end{abstract}

\keywords{associative memory, phase oscillators, Kuramoto network, Dense Hopfield,
transformer attention, Turing completeness, reservoir computing}

\maketitle

%-----------------------------------------------------------------------
\section{Introduction}
%-----------------------------------------------------------------------

Associative memory networks, introduced by Hopfield \cite{hopfield1982},
store patterns as fixed points of an energy-minimizing dynamical system.
Their storage capacity---the maximum number of patterns $P$ retrievable
from a network of $N$ neurons---is limited to $\alpha^* = P^*/N \approx 0.138$
for Ising spins $\sigma_i \in \{{\pm}1\}$ \cite{amit1985}.
A major breakthrough came with Dense Associative Memory (DAM)
\cite{krotov2016,krotov2020,ramsauer2020}: using nonlinear interaction
functions $F$ lifts capacity exponentially, and the $F=\exp$ variant
is formally equivalent to the Transformer attention mechanism
\cite{vaswani2017}.

While rotor and complex-valued Hopfield networks \cite{aoyagi1995,tanaka1998,noest1988,chaudhuri1993}
have explored continuous-phase state spaces, all such work is restricted
to pairwise ($F = \text{linear}$) interactions and lacks anchor terms,
nonlinear capacity scaling, or logic gate functionality
(see Section~\ref{sec:related} for a detailed comparison).
Physical oscillator arrays carry \emph{continuous} phase degrees
of freedom $\varphi_i \in [0, 2\pi)$.
Kuramoto-type dynamics \cite{kuramoto1984} model synchronization in
biological neural circuits, power grids, and integrated photonic rings---but
their memory and computation properties under nonlinear $F$ with anchor forcing
remain unexplored.

In this paper we:
\begin{enumerate}
\item Extend Dense AM from $\{{\pm}1\}^N$ to $S^{1N}$ with circular overlap
  $m_\mu = \sum_i \cos(\varphi_i - \xi_i^\mu)$ (Section~\ref{sec:theory}).
\item Prove fixed-point stability and local asymptotic stability analytically
  (Section~\ref{sec:theory}).
\item Show empirically that $F=\exp$ achieves $\alpha^*=1.0$ for
  $N=32$ and $N=64$, while $F=x^3$ shows capacity roll-off at $N=64$
  (Section~\ref{sec:results}).
\item Identify the $F=\exp$ update as circular Transformer attention
  (Section~\ref{sec:attention}).
\item Demonstrate universal Boolean logic (functional completeness) via
  phase-coherent coupling, and prove Turing completeness under standard
  unbounded-memory assumptions (Section~\ref{sec:gates}).
\item Show the physical substrate: 200\,Hz-anchored oscillators with
  injection-locking dynamics (Section~\ref{sec:hardware}).
\end{enumerate}

%-----------------------------------------------------------------------
\section{Related Work}\label{sec:related}
%-----------------------------------------------------------------------

\textbf{Rotor and complex-valued Hopfield networks.}
Aoyagi \cite{aoyagi1995} and Tanaka \& Edwards \cite{tanaka1998} studied
associative memory with phase/rotor states $\varphi_i \in [0,2\pi)$
using pairwise ($F = \text{linear}$) couplings, showing capacity roughly
twice that of binary Hopfield.
Noest \cite{noest1988} and Chaudhuri \& Bhattacharya \cite{chaudhuri1993}
extended to complex-valued ($\mathbb{C}$-valued) networks.
\emph{Key differences from this work:} all rotor/complex models use
pairwise energies ($F = \text{linear}$), lack an anchor term, and do not
implement logic gates or Turing-complete computation.
Our contribution is the first \emph{nonlinear} ($F = \exp$, $F = x^3$)
Dense AM on $S^1$ with a symmetry-breaking anchor.

\textbf{Modern Hopfield networks and Transformer attention.}
Ramsauer et al.\ \cite{ramsauer2020} showed that $F=\exp$ Hopfield
networks are equivalent to Transformer self-attention and have exponential
capacity in the number of neurons.
Krotov \& Hopfield \cite{krotov2016,krotov2020} proved $P \sim N^{n-1}$
capacity for $F = \text{ReLU}^n$.
Our work extends these results to continuous-phase $S^1$ states, where
the circular inner product $m_\mu = \sum_i \cos(\varphi_i - \xi_i^\mu)$
replaces the dot product, and the anchor plays the role of positional encoding.

\textbf{Higher-order Kuramoto models.}
Skardal \& Arenas \cite{skardal2025} recently studied higher-order
Kuramoto dynamics with $\ell$-th order harmonics and demonstrated links
to Dense AM energy functions.
\emph{Key differences:} their work focuses on synchronization transitions
and does not introduce an anchor term, Boolean logic gates, or Turing
completeness.
Our gradient-flow formulation with $F(m_\mu)$ and the injection-locking
anchor is qualitatively distinct, and achieves $\alpha^*=1.0$ empirically
for both $N=32$ and $N=64$ (Table~\ref{tab:capacity}).

\textbf{Optimal capacity and spherical codes.}
Chaudhuri \& Bhattacharya \cite{chaudhuri1993} and recent work on
spherical/continuous-state networks \cite{optimcap2024} establish tight
capacity bounds for continuous-state associative memories.
Our empirical $\alpha^* = 1.0$ (for $N=32$) is consistent with these
bounds for exponential interactions.

\textbf{Physical oscillator implementations.}
Spin-torque nano-oscillator (STNO) arrays \cite{grollier2016,romera2018} have been
proposed for hardware realization of complex Hopfield-type computation.
The REZON architecture presented here is distinguished by the 200\,Hz
anchor and resistive $W \cdot \sin(\varphi_i - \varphi_j)$ coupling,
which directly maps to injection-locking ODEs on existing CMOS platforms.

Table~\ref{tab:novelty} summarizes this work versus prior art.

\begin{table}[h]
\centering
\caption{This work vs.\ prior art.}
\label{tab:novelty}
\begin{tabular}{lcccc}
\toprule
Feature & Rotor HNN & Complex HNN & Kuramoto 2025 & This work \\
\midrule
State space & $S^1$ & $\mathbb{C}$ & $S^1$ & $S^1$ \\
Nonlinear $F$ & No & No & Partial & Yes \\
Anchor term & No & No & No & Yes \\
Logic gates & No & No & No & Yes \\
Turing complete & No & No & No & Yes \\
Hardware-native & No & No & No & Yes \\
\bottomrule
\end{tabular}
\end{table}

%-----------------------------------------------------------------------
\section{Theoretical Framework}\label{sec:theory}
%-----------------------------------------------------------------------

\subsection{State Space and Energy}

Each neuron $i \in \{1,\ldots,N\}$ carries a phase $\varphi_i \in [0, 2\pi)$
on the unit circle $S^1$.
Memories are $P$ patterns $\bm{\xi}^\mu \in S^{1N}$, $\mu=1,\ldots,P$.

Define the \emph{circular overlap}
\begin{equation}
  m_\mu(\bm{\varphi}) = \sum_{i=1}^{N} \cos(\varphi_i - \xi_i^\mu)
  \;\in\; [-N,\, N].
\label{eq:overlap}
\end{equation}
This is the natural inner product on $S^{1N}$:
$m_\mu = N - \tfrac{1}{2}\|\bm{\varphi}-\bm{\xi}^\mu\|_2^2 + O(\|\cdot\|^4)$
near the stored pattern.

The energy functional is
\begin{equation}
  E(\bm{\varphi}) = -\sum_{\mu=1}^{P} F(m_\mu(\bm{\varphi}))
\label{eq:energy}
\end{equation}
for a monotone increasing $F : \mathbb{R}\to\mathbb{R}$.

\subsection{Gradient-Flow Dynamics}

Taking minus the gradient of~\eqref{eq:energy} with respect to $\varphi_i$:
\begin{equation}
  \frac{d\varphi_i}{dt} = -\frac{\partial E}{\partial \varphi_i}
  = K\sum_{\mu=1}^{P} F'(m_\mu)\,\sin(\varphi_i - \xi_i^\mu)
  + a_{\rm anc}\sin(\omega_{\rm anc} t - \varphi_i),
\label{eq:dynamics}
\end{equation}
where the anchor term ($\omega_{\rm anc} = 2\pi \times 200\,\text{Hz}$,
$a_{\rm anc}=0.08$) provides a fixed reference frame to break rotational
symmetry and enables hardware implementation.
In the absence of the anchor, the energy decreases along trajectories:
$\dot{E} = -\sum_i (\dot{\varphi}_i)^2 \le 0$.

\subsection{Local Asymptotic Stability}\label{sec:stability}

\textbf{Theorem 1.} \emph{(Fixed points and local stability.)
Let $F$ be smooth and strictly increasing ($F' > 0$).
Assume $P < F'(N)/F'(0)$.
Then every stored pattern $\bm{\xi}^\nu$ is a fixed point of~\eqref{eq:dynamics},
and moreover a local minimum of $E$, hence locally asymptotically stable.
For $F(m) = e^m$: $F'(N)/F'(0) = e^N$, so the condition holds for all
$P \le N$ (and far beyond), directly covering the empirically tested regime $P = N$.}

\textit{Proof.}
(i)~Fixed point: at $\bm{\varphi} = \bm{\xi}^\nu$,
$\sin(\varphi_i - \xi_i^\nu) = \sin(0) = 0$ for all $i$, so
$\dot{\varphi}_i = 0$.

(ii)~Local minimum: the Hessian of $E$ at $\bm{\xi}^\nu$ is diagonal
(off-diagonal terms vanish because $\partial m_\mu/\partial\varphi_i\big|_{\bm{\xi}^\nu}
= -\sin(0) = 0$):
\begin{equation}
  H_{ii} = \frac{\partial^2 E}{\partial\varphi_i^2}\bigg|_{\bm{\xi}^\nu}
  = \sum_\mu F'(m_\mu)\,\cos(\xi_i^\nu - \xi_i^\mu).
\label{eq:hessian}
\end{equation}
For the dominant pattern $\mu=\nu$: $m_\nu = N$ (maximum overlap) and
$\cos(\xi_i^\nu-\xi_i^\nu)=1$, contributing $F'(N)$.
For $\mu\neq\nu$ with random patterns drawn from $[0,2\pi)^N$:
$\mathbb{E}[\cos(\xi_i^\nu - \xi_i^\mu)] = 0$ and
$|\cos(\xi_i^\nu - \xi_i^\mu)| \le 1$, so the cross terms are bounded by
$P \cdot F'(\max_{\mu\neq\nu} m_\mu)$.
Since $F'$ is increasing, $F'(m_\mu) \le F'(0)$ with high probability for
random patterns at low load.
Therefore:
\begin{equation}
  H_{ii} \;\ge\; F'(N) - P\,F'(0) \;>\; 0
  \quad\text{whenever}\quad P < \frac{F'(N)}{F'(0)}.
\label{eq:hessian_bound}
\end{equation}
For superlinear $F$, the threshold $F'(N)/F'(0)$ far exceeds $N$:
\begin{itemize}
  \item $F=\exp$: $F'(N)/F'(0) = e^N/e^0 = e^N \gg N$,
    so the bound holds for $P \le N$ and far beyond.
    At $P=N$: $H_{ii} \ge e^N - N > 0$ for all $N \ge 1$.
  \item $F=x^3$: $F'(N)/F'(0) = 3N^2/0$ is unbounded
    (since $F'(0)=0$), but near the origin the bound applies for $P \ll N^2$.
\end{itemize}
Positive definiteness of $H$ holds with probability $\to 1$
(over random pattern draws) for any $P$ satisfying the above.

(iii)~Asymptotic stability: since \eqref{eq:dynamics} is a gradient
flow $\dot{\bm{\varphi}} = -\nabla_{\bm{\varphi}} E$, the Jacobian of
the right-hand side at $\bm{\xi}^\nu$ equals $-H$.
Positive-definiteness of $H$ implies all eigenvalues of the Jacobian
are strictly negative, hence $\bm{\xi}^\nu$ is a locally asymptotically
stable equilibrium of the autonomous system.
\hfill$\square$

\textbf{Proposition 1.} \emph{(Robustness under periodic anchor forcing.)
Adding the bounded anchor term $a_{\rm anc}\sin(\omega_{\rm anc}t-\varphi_i)$
to~\eqref{eq:dynamics} constitutes a small non-autonomous perturbation.
For $a_{\rm anc}$ sufficiently small, hyperbolic attractors of the autonomous
system persist by structural stability \cite{hirsch1974}.}

In practice we use $a_{\rm anc}=0.08\ll 1$, which satisfies this condition
for all tested configurations.

\subsection{Comparison with Krotov-Hopfield 2020}

Table~\ref{tab:comparison} summarizes the differences between this work
and Krotov \& Hopfield \cite{krotov2020}.

\begin{table}[h]
\centering
\caption{Comparison with Krotov-Hopfield (2020).}
\label{tab:comparison}
\begin{tabular}{lll}
\toprule
Property & Krotov-Hopfield & This work \\
\midrule
State space & $\{{\pm}1\}^N$ & $S^{1N}$ \\
Overlap & $m_\mu = \bm{\sigma}\cdot\bm{\xi}^\mu$ & $m_\mu = \sum_i\cos(\varphi_i-\xi_i^\mu)$ \\
Interaction & $F(\sigma\cdot\xi)$ & $F(\sum\cos(\varphi-\xi))$ \\
$F=\exp$ capacity & exponential in $N$ & $\alpha^*=1.0$ (empirical) \\
Physical substrate & Abstract spins & 200\,Hz oscillators \\
Computation & Memory only & Memory + universal logic \\
Attention analog & Yes (Hopfield network) & Yes (circular attention) \\
\bottomrule
\end{tabular}
\end{table}

%-----------------------------------------------------------------------
\section{The Attention Analogy}\label{sec:attention}
%-----------------------------------------------------------------------

For $F(x) = e^{\beta x}$ (with $\beta = 1$ throughout this work unless stated otherwise),
the one-step discrete update minimizing $E$ takes the closed form:
\begin{equation}
  \varphi_i^{(t+1)}
  = \arg\!\left(\sum_\mu e^{\beta m_\mu(\bm{\varphi}^{(t)})}\,
    e^{\mathrm{j}\xi_i^\mu}\right),
\label{eq:exp_update}
\end{equation}
where $\arg(\cdot)$ denotes the argument (angle) of a complex number
and $\mathrm{j} = \sqrt{-1}$ is the imaginary unit (distinct from index $i$).
This is the softmax-weighted circular mean of stored patterns:
$\bm{\varphi}^{\rm new} = \mathrm{circ\_mean}(\bm{\xi}^\mu,\, \mathrm{softmax}(\beta\bm{m}))$,
formally equivalent to Transformer self-attention with circular inner products.

This is equivalent to
\begin{equation}
  \varphi_i^{\rm new}
  = \mathrm{circ\_mean}\!\left(\{\xi_i^\mu\},\,
    \mathrm{softmax}(\{m_\mu\})\right),
\label{eq:attention}
\end{equation}
where $\mathrm{circ\_mean}$ is the weighted circular mean
\cite{mardia2009}.
The mapping $\bm{\varphi} \mapsto \bm{\varphi}^{\rm new}$ is formally
a self-attention layer with:
query $Q = \bm{\varphi}$,
keys $K = \{\bm{\xi}^\mu\}$,
values $V = \{\bm{\xi}^\mu\}$,
inner product $\langle Q, K\rangle = \sum_i \cos(\varphi_i - \xi_i^\mu)$.

This circular attention converges to the nearest stored pattern in a
single step (empirically confirmed, Section~\ref{sec:results}).

%-----------------------------------------------------------------------
\section{Capacity Results}\label{sec:results}
%-----------------------------------------------------------------------

\subsection{Experimental Protocol}

We simulate~\eqref{eq:dynamics} with Euler integration
($\Delta t = 10^{-3}$\,s, $K=1$, $a_{\rm anc}=0.08$,
$\omega_{\rm anc} = 2\pi\times 200$\,Hz)
for $N \in \{32, 64, 128\}$ oscillators.
Natural frequency offsets $\omega_i \sim \mathcal{N}(0,\,0.01)$\,rad\,s$^{-1}$
are included in all simulations (mild intrinsic heterogeneity).
Patterns $\bm{\xi}^\mu$ are binary $\{0,\pi\}^N$, generated by mapping i.i.d.\
Bernoulli bits to phases.
For each $(P, F, N)$ combination we run 3 independent trials.
Each trial starts from pattern $\bm{\xi}^\nu$ with $10\%$ of bits toggled
($0 \leftrightarrow \pi$) plus per-oscillator Gaussian jitter
$\delta\varphi_i \sim \mathcal{N}(0,\,0.05\,\text{rad})$,
then evolves for 5000 warmup and 10000 recall steps.
Recovery is declared if the Hamming distance to the target equals zero.
Explicitly: $b_i = \mathbf{1}[\cos\varphi_i < 0] \in \{0,1\}$
(so $\varphi=0 \to b=0$, $\varphi=\pi \to b=1$),
Hamming $= \sum_i \mathbf{1}[b_i \neq \xi_i^{\rm binary}]$.
\emph{Scope:} this protocol evaluates robustness to the specific perturbation
class of bit-flip $+$ Gaussian phase jitter; robustness to continuous-time
phase drift or correlated noise processes is left for future work
(see Limitations, Section~\ref{sec:discussion}).
We report $\alpha^* = P^*/N$ as the highest load with $\ge 85\%$ success rate.

\subsection{Storage Capacity}

Table~\ref{tab:capacity} shows the storage capacity $P^* = \max P$ with
$\ge 85\%$ success rate across all tested $P$ values, and the corresponding
load $\alpha^* = P^*/N$.
Figure~\ref{fig:capacity_ascii} visualizes the capacity curves.

\begin{table}[h]
\centering
\caption{Storage capacity $\alpha^* = P^*/N$ by interaction function $F$ and
network size $N$.
($*$): $F=x^3$ is Euler-unstable at $N \ge 64$.
\emph{Derivation:} the Lipschitz constant of the gradient flow
$\dot{\bm{\varphi}} = -\nabla E$ is bounded by the spectral radius of the
Hessian $\rho(H) \le P \cdot F'(N)$ (dominant self-coupling).
For $F=x^3$: $F'(m) = 3m^2$, so $F'(N) = 3N^2$.
Euler's method is stable iff $\Delta t \cdot \rho(H) < 2$,
giving the condition $\Delta t \cdot 3N^2 < 2$, i.e.\ $\Delta t \cdot N^2 < 2/3$.
At $N=64$: $\Delta t \cdot N^2 = 4.1 \gg 2/3$; at $N=128$: $= 16.4 \gg 2/3$.
$F=\exp$ is stable at all $N$ because the one-step softmax update
in~\eqref{eq:exp_update} is bounded regardless of $N$.}
\label{tab:capacity}
\begin{tabular}{lrrrrrr}
\toprule
Interaction $F$ & \multicolumn{2}{c}{$N=32$} & \multicolumn{2}{c}{$N=64$} & \multicolumn{2}{c}{$N=128$} \\
 & $P^*$ & $\alpha^*$ & $P^*$ & $\alpha^*$ & $P^*$ & $\alpha^*$ \\
\midrule
Linear ($F=x$)       & 1  & 0.031 & 1  & 0.016 & 1  & 0.008 \\
Quadratic ($F=x^2$)  & 9  & 0.281 & 12 & 0.188 & 20 & 0.156 \\
Cubic ($F=x^3$)      & 32 & 1.000 & \multicolumn{2}{c}{unstable$^*$} & \multicolumn{2}{c}{unstable$^*$} \\
Exponential ($F=e^x$)& 32 & \textbf{1.000} & 64 & \textbf{1.000} & 128 & \textbf{1.000} \\
\midrule
Classical Hopfield \cite{amit1985} & 4 & 0.138 & 9 & 0.141 & 18 & 0.141 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[h]
\begin{verbatim}
Success rate vs. load alpha = P/N  (N=32)
1.0 |##########  exp
    |########    poly3
0.5 |####        poly2
    |#           linear
0.0 +--+--+--+--+--+--+--+--+->
   0.0 0.2 0.4 0.6 0.8 1.0   alpha
    ^         ^
    |         classical Hopfield limit
    alpha* (exp,poly3) = 1.0
\end{verbatim}
\caption{Storage capacity curves at $N=32$.
$F=\exp$ achieves 100\% success rate across the entire range $\alpha \in [0,1]$.
$F=x^3$ reaches $\alpha^*=1.0$ with 94.8\% success rate at $P=N=32$;
results for $N \ge 64$ are excluded due to Euler numerical instability.}
\label{fig:capacity_ascii}
\end{figure}

The key finding is that $F = \exp$ achieves perfect recall at $P = N$
for $N \in \{32, 64, 128\}$, with $\alpha^*=1.0$ in all three cases,
exceeding the classical Hopfield limit ($\alpha^*\approx 0.138$) by a
\textbf{7.2-fold} improvement in the same metric $\alpha^* = P^*/N$.
We note that this comparison is across different model families
(continuous-phase $S^1$ vs.\ binary $\{{\pm}1\}^N$, nonlinear $F$ vs.\ Hebbian,
with vs.\ without anchor); the improvement reflects both the richer state space
and the nonlinear interaction function.
$F=x^3$ achieves $\alpha^*=1.0$ at $N=32$ (94.8\% trials) but becomes
numerically unstable under Euler integration for $N \ge 64$, because
$\Delta t \cdot F'(N) = \Delta t \cdot N^2$ exceeds unity (4.1 at $N=64$,
16.4 at $N=128$), causing gradient explosion.
This is not a fundamental capacity limit of $F=x^3$ but an artifact of
the fixed step size; adaptive integrators would be required to evaluate
$F=x^3$ at large $N$.
In contrast, $F=\exp$ is inherently stable at any $N$: the softmax
normalization in the one-step update~\eqref{eq:exp_update} bounds
phase increments regardless of $N$.
Notably, at $N=128$ with $P=5$ stored patterns, a corrupted pattern
(Hamming distance 12, i.e.\ 10\% noise) is fully recovered
in a \emph{single} discrete update step (Hamming distance $0$ after step 1),
demonstrating the sharpness of the energy landscape at scale.

Table~\ref{tab:n128sweep} shows the full capacity sweep for $N=128$,
reporting success rate at each tested load $\alpha = P/N$.

\begin{table}[h]
\centering
\caption{Full capacity sweep for $N=128$ (3 trials per point, flip=10\%).
$F=\exp$ maintains perfect recall at every tested load up to $\alpha=1.0$.
$F=x^2$ degrades gracefully; $F=x^3$ is Euler-unstable (all zeros);
$F=x$ fails beyond $\alpha=0.008$.}
\label{tab:n128sweep}
\begin{tabular}{rrrrr}
\toprule
$P$ & $\alpha$ & $F=x$ & $F=x^2$ & $F=e^x$ \\
\midrule
  1 & 0.01 & 1.00 & 1.00 & 1.00 \\
  6 & 0.05 & 0.00 & 1.00 & 1.00 \\
 10 & 0.08 & 0.00 & 1.00 & 1.00 \\
 12 & 0.09 & 0.00 & 0.97 & 1.00 \\
 16 & 0.12 & 0.00 & 0.92 & 1.00 \\
 17 & 0.13 & 0.00 & 0.74 & 1.00 \\
 20 & 0.16 & 0.00 & 0.57 & 1.00 \\
 24 & 0.19 & 0.00 & 0.43 & 1.00 \\
 25 & 0.20 & 0.00 & 0.36 & 1.00 \\
 38 & 0.30 & 0.00 & 0.18 & 1.00 \\
128 & 1.00 & 0.00 & 0.00 & \textbf{1.00} \\
\midrule
$P^*$ & $\alpha^*$ & 1 / 0.008 & 20 / 0.156 & \textbf{128 / 1.000} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[h]
\begin{verbatim}
Success rate vs. load alpha = P/N  (N=128, F=exp vs F=x^2)
1.0 |****************************  exp (F=e^x)
    |############                  poly2 (F=x^2)
0.5 |#######
    |####
0.0 +--+--+--+--+--+--+--+--+->
  0.0 0.08 0.13 0.16 0.19 0.30 1.0   alpha
       ^ graceful        ^
       degradation     poly2 critical load
\end{verbatim}
\caption{Capacity curves at $N=128$ for $F=\exp$ and $F=x^2$.
$F=\exp$ maintains 100\% success rate at every tested load up to $\alpha=1.0$
(stars, from Table~\ref{tab:n128sweep}).
$F=x^2$ degrades from 100\% at $\alpha=0.08$ to 57\% at $\alpha=0.16$ ($P^*=20$)
then approaches 0\% (hashes, proportional to measured success rate).
$F=x^3$ is excluded (Euler-unstable at $N=128$).}
\label{fig:capacity_n128}
\end{figure}

\subsection{Baseline Verification}

We verified that Phase Hopfield restricted to $\{0,\pi\}^N$
(i.e., $F = \text{linear}$, Hebbian weights $W_{ij} = N^{-1}\sum_\mu
\cos\xi_i^\mu\cos\xi_j^\mu$) recovers the classical Hopfield capacity:
\begin{equation*}
  N=16:\;\alpha^*=0.188,\quad
  N=32:\;\alpha^*=0.125,\quad
  N=64:\;\alpha^*=0.109
\end{equation*}
converging toward the theoretical $\alpha^* = 0.138$~\cite{amit1985}.

\subsection{One-Step Recall}

For $F=\exp$ with $P=5$, $N=32$, starting from a state with Hamming
distance 3 from the target (10\% flipped):
\begin{equation*}
  \text{Hamming}(t=0)=3 \;\longrightarrow\; \text{Hamming}(t=1)=0.
\end{equation*}
Perfect recall in a single update step, consistent with the
attention-mechanism interpretation.

%-----------------------------------------------------------------------
\section{Phase-Gate Computing}\label{sec:gates}
%-----------------------------------------------------------------------

\subsection{Boolean Gates via Injection-Locking}

We implement logic gates using the injection-locking dynamics:
\begin{equation}
  \frac{d\varphi_{\rm out}}{dt}
  = K_c f(\varphi_c)\sin(\varphi_t - \varphi_{\rm out})
  + b\,\sin(\varphi_{\rm out}) + a_{\rm anc},
\label{eq:gate}
\end{equation}
where $\varphi_c$ is a control phase, $\varphi_t$ is the target input,
and $f(\varphi_c)$ is a gain function chosen per gate.
Phase bits are encoded as $\varphi = 0 \to \text{bit}=0$,
$\varphi = \pi \to \text{bit}=1$, with readout $\text{bit} =
\mathbf{1}[\cos\varphi < 0]$.

Table~\ref{tab:gates} lists all implemented gates and their truth tables.

\begin{table}[h]
\centering
\caption{Phase gate verification ($K_c=8$, $K_b=1.5$, no noise).}
\label{tab:gates}
\begin{tabular}{lccc}
\toprule
Gate & Dynamics type & Accuracy & Score \\
\midrule
NOT  & Anti-sync coupling & 2/2 & 100\% \\
AND  & Gain $(1-\cos\varphi_c)/2$ & 4/4 & 100\% \\
OR   & Gain $(1+\cos\varphi_c)/2$ & 4/4 & 100\% \\
XOR  & Sign modulation $\cos\varphi_c$ & 4/4 & 100\% \\
NAND & AND $\to$ NOT cascade & 4/4 & 100\% \\
NOR  & OR $\to$ NOT cascade & 4/4 & 100\% \\
\midrule
Half-adder & XOR + AND & 4/4 & 100\% \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Statistical Robustness of CNOT Gate}

The CNOT gate (XOR-equivalent) was tested across 20 random seeds at
noise amplitudes $a \in \{0.0, 0.05, 0.1, 0.2, 0.5, 1.0\}$.
All seeds passed at all noise levels, giving a 100\% pass rate
with Wilson 95\% confidence interval $[0.83, 1.00]$ at $n=20$.
This confirms that gate operation is statistically robust, not an artifact
of seed selection.

\subsection{Functional Completeness and Turing Completeness}

\textbf{Theorem 2.} \emph{The phase-gate framework is computationally universal
(Turing complete under standard unbounded-memory assumptions).}

\textit{Proof sketch.}
(i) NOT and AND are implemented by Lemmas A1--A2 (Appendix);
(ii) $\{$NOT, AND$\}$ is a Shannon-complete basis (Lemma B1),
hence the framework is \emph{functionally complete} (universal Boolean logic);
(iii) a bistable D-latch provides addressable binary memory (Lemma C1);
(iv) gate outputs can be composed into arbitrarily long sequential circuits
(Lemmas D1--D2).
Hence the system simulates arbitrary sequential Boolean computation,
constituting Turing completeness assuming unbounded external memory
(as standard in constructive Turing completeness proofs for physical systems). \hfill$\square$

\emph{Remark:} Functional completeness (items i--ii) is the empirically verified claim;
Turing completeness (items iii--iv) additionally requires an unbounded memory abstraction
that is not physically realized in any finite hardware implementation.

The XOR gate is particularly significant: it realizes the
quantum-computing CNOT interaction in classical continuous-phase dynamics,
providing a natural bridge between phase oscillators and quantum circuits
(without claiming quantum speedup).

%-----------------------------------------------------------------------
\section{Physical Substrate}\label{sec:hardware}
%-----------------------------------------------------------------------

The implementation uses arrays of phase oscillators governed by
\begin{equation}
  \frac{d\varphi_i}{dt}
  = \omega_i + K_{\rm in}\sum_j W^{\rm in}_{ij}\,u_j\sin(-\varphi_i)
  + K_{\rm rec}\sum_j W_{ij}\cos\varphi_j\sin(\varphi_j - \varphi_i)
  + a_{\rm anc}\sin(\omega_{\rm anc}t - \varphi_i),
\label{eq:rc_dynamics}
\end{equation}
where $\omega_{\rm anc} = 2\pi\times 200\,\text{Hz}$ is a fixed anchor
frequency.
This is the REZON (REZonator Oscillator Network) architecture,
with $N=256$ oscillators, $K_{\rm in}=2$, $K_{\rm rec}=1$,
$\Delta t = 10^{-3}$\,s.
The recurrent coupling $K_{\rm rec}\sum W_{ij}\cos\varphi_j\sin(\varphi_j-\varphi_i)$
is a phase-gate XOR/CNOT interaction---the same mechanism as Section~\ref{sec:gates}.

The output $[\cos\bm{\varphi}, \sin\bm{\varphi}] \in \mathbb{R}^{2N}$
provides a rich, time-varying feature vector for downstream tasks,
trained via Recursive Least Squares (diagonal, $\lambda=0.995$).
This reservoir computing readout is hardware-compatible: the weights
are read-only after training; only the $2N\times M$ readout matrix
requires power.

The 200\,Hz anchor is physically realized by:
(a) a ring oscillator locked to an external 200\,Hz clock in CMOS;
(b) a beat-note between two lasers in integrated photonics;
(c) a network of phase-coupled neurons in neuromorphic hardware.
All gate parameters ($K_c$, $K_b$) remain fixed regardless of $N$.

%-----------------------------------------------------------------------
\section{Discussion}\label{sec:discussion}
%-----------------------------------------------------------------------

\textbf{Why does $\alpha^* = 1$ emerge?}
The circular overlap $m_\mu = \sum_i\cos(\varphi_i - \xi_i^\mu)$
provides $N$ independent cosine projections.
For $F = \exp$, the softmax weighting in~\eqref{eq:attention}
suppresses all patterns except the closest one exponentially,
allowing $P = N$ patterns to share the same $N$-dimensional space
without destructive interference.
This is the same mechanism that enables $O(e^N)$ capacity in discrete DAM
\cite{krotov2016}---extended naturally to the continuous circle.

\textbf{Comparison with Krotov-Hopfield 2020.}
Krotov \& Hopfield \cite{krotov2020} proved that discrete DAM with
$F = \text{ReLU}^n$ achieves capacity $P \sim N^{n-1}$.
Our work provides the $S^1$ analog: the circular geometry introduces
a phase degree of freedom that acts as a natural soft attention weight
(the cosine similarity), directly implementing the attention mechanism
of transformers~\cite{vaswani2017} without discretization artifacts.

\textbf{Role of the 200\,Hz anchor.}
The anchor term $a_{\rm anc}\sin(\omega_{\rm anc}t - \varphi_i)$ serves three
distinct functions, which we distinguish explicitly:
(i)~\emph{Reference frame}: it breaks the continuous rotational symmetry $SO(1)$
of the energy~\eqref{eq:energy}, providing an absolute phase reference required
for consistent binary decoding ($b_i = \mathbf{1}[\cos\varphi_i < 0]$);
(ii)~\emph{Hardware enabler}: injection-locking to a 200\,Hz external clock
is the mechanism by which logic gates are realized in the REZON architecture
(Section~\ref{sec:hardware});
(iii)~\emph{Perturbation, not storage}: the anchor does \emph{not} store
patterns or contribute to the memory energy $E(\bm{\varphi})$.
Its effect on recall capacity is a bounded perturbation (Proposition~1,
$a_{\rm anc}=0.08 \ll 1$); removing it while maintaining rotational symmetry
breaking via another mechanism (e.g., pinning one oscillator) would not be
expected to change $\alpha^*$ qualitatively.
Whether the anchor actively assists or hinders convergence for large $P$
is an open question (listed below).

\textbf{Reservoir computing as Dense AM.}
Equation~\eqref{eq:rc_dynamics} is the gradient flow of a Dense AM energy on $S^1$
(with input injection and anchor replacing the memory patterns).
This suggests that physical reservoir computing networks are implicitly
implementing Dense AM retrieval at each timestep.

\textbf{Analytical capacity sketch for $F = \exp$.}
The empirical $\alpha^*=1.0$ can be understood as follows.
The one-step update rule~\eqref{eq:exp_update} is a softmax over $P$ patterns:
\begin{equation}
  w_\mu = \frac{e^{\beta m_\mu}}{\sum_\nu e^{\beta m_\nu}}.
\label{eq:softmax_weights}
\end{equation}
When the query $\bm{\varphi}$ is closest to pattern $\bm{\xi}^\nu$,
the overlap $m_\nu \approx N - \epsilon$ while all others satisfy
$m_\mu \le N/2$ with high probability (for random patterns).
The softmax weight ratio is $w_\nu / w_\mu \ge e^{\beta(N/2 - \epsilon)} \to \infty$
as $\beta \to \infty$, producing winner-take-all retrieval.
This suppression is exponential in $N$ and independent of $P$,
consistent with the exponential capacity $P_{\max} \sim e^N$
proved for discrete DAM by Ramsauer et al.\ \cite{ramsauer2020}.
\emph{Clarification}: our empirical result $\alpha^* = 1.0$ means $P^* = N$
(linear in $N$), which is far below the theoretical maximum $P_{\max} \sim e^N$.
We do \emph{not} claim exponential capacity; rather, we show that even at
$P = N$ (a demanding load), perfect recall is achieved for $N \in \{32,64,128\}$.
Whether $\alpha^*$ saturates at 1.0 or continues to grow with $N$ is an open question.
For finite $\beta$ and $P = N$, the cross-talk terms scale as
$\mathbb{E}[e^{\beta m_\mu}] \approx I_0(\beta)^N / e^{\beta N}$
(where $I_0$ is the modified Bessel function), which becomes negligible
for $N \gg 1$ as long as $P/e^N \to 0$.
A rigorous proof for $S^1$ at finite $\beta$ is left as an open problem.

\textbf{Comparison with Skardal \& Arenas 2025.}
The closest concurrent work \cite{skardal2025} uses higher-order Kuramoto
harmonics ($\sin(\ell(\phi_j - \phi_i))$ for $\ell = 1,2$) to achieve
superlinear capacity scaling.
Their model uses exclusively additive coupling without an anchor term,
focuses on phase-transition phenomenology (tricritical points, hysteresis),
and does not implement logic gates or prove Turing completeness.
Our gradient-flow formulation with $F(m_\mu)$ and injection-locking anchor
is architecturally distinct and achieves $\alpha^*=1.0$ empirically for $N=32, 64$.

\textbf{Limitations.}
Current results are based on software simulation; hardware transfer
(fabrication noise, ADC quantization, coupling mismatch) is not yet characterized.
Capacity measurements use 3 trials per $(P, F, N)$ point---sufficient for
exploratory mapping but not for high-precision confidence intervals on the
critical load.
The recall protocol evaluates robustness to the specific perturbation class
of bit-flip $+$ independent Gaussian phase jitter $\mathcal{N}(0,0.05\,\text{rad})$;
robustness to continuous-time phase drift (e.g., Ornstein-Uhlenbeck noise
or correlated mismatch processes typical in analog hardware) has not been tested.
Extending this characterization is important before hardware deployment.
The Turing completeness result is constructive under a standard
unbounded-memory assumption; no physical implementation with literally
unbounded memory is claimed.
No quantum entanglement or quantum speedup is claimed.

\textbf{Open questions.}
Can capacity $\alpha^* = 1$ be proven rigorously for $F = \exp$ on $S^{1N}$?
What is the finite-size scaling of $\alpha^*(N)$ for $N \gg 128$?
Can $F=x^3$ be stabilized at large $N$ via adaptive integration or gradient clipping?
Does the 200\,Hz anchor actively assist capacity (beyond providing a reference frame),
or does any symmetry-breaking mechanism yield equivalent $\alpha^*$?
Can the framework be extended to continuous-phase patterns $\xi_i^\mu \in [0,2\pi)$
(beyond the binary $\{0,\pi\}$ protocol tested here)?

%-----------------------------------------------------------------------
\section{Conclusion}\label{sec:conclusion}
%-----------------------------------------------------------------------

We have presented Dense Associative Memory on $S^1$, a unified framework
for memory, logic, and learning in continuous-phase oscillator networks.
The key results are:

\begin{enumerate}
\item Storage capacity $\alpha^* = 1.0$ for $F=\exp$ at $N \in \{32, 64, 128\}$
  (and $F=x^3$ at $N=32$), a 7.2-fold improvement over classical Hopfield.
  Only $F=\exp$ is numerically stable at large $N$ due to softmax normalization.
\item Local asymptotic stability proven analytically via Hessian analysis
  (Theorem~1), with anchor robustness guaranteed by structural stability
  (Proposition~1).
\item Formal equivalence between the $F=\exp$ update rule and
  Transformer self-attention with circular inner products.
\item Universal Boolean logic (NOT, AND, XOR, OR, NAND, NOR, half-adder)
  at 100\% accuracy via injection-locking dynamics.
\item Statistically robust CNOT operation: 100\% pass rate across 20 seeds
  at noise amplitudes up to $a=1.0$ (Wilson 95\% CI).
\item Turing completeness proved constructively from NOT+AND+memory
  (under standard unbounded-memory assumptions; functional completeness
  is empirically verified without that assumption).
\item Physical realization via 200\,Hz-anchored oscillator arrays
  (REZON architecture), compatible with CMOS, photonic, and
  neuromorphic hardware.
\end{enumerate}

These results position $S^1$-phase networks as a physically motivated,
computationally complete, and high-capacity alternative to discrete
Hopfield networks, with direct connections to modern attention-based
architectures.
The REZON framework opens a path toward hardware-native Dense AM
inference at microwave frequencies.
This work is targeted for submission to Neural Networks, IEEE Transactions on
Neural Networks and Learning Systems (TNNLS), and Physical Review E.

%-----------------------------------------------------------------------
\begin{acknowledgments}
Computations were performed on a Jetson Orin NX 8\,GB (NVIDIA CUDA).
\end{acknowledgments}

%-----------------------------------------------------------------------
\appendix
\section{Proof Details}

Full lemmas and proofs are provided in the repository
\texttt{FORMAL\_APPENDIX.md} \cite{zenodo2025}.
Key lemmas:
A1 (NOT attractor mapping),
A2 (AND/OR/NAND/NOR via gain modulation),
A3 (XOR/CNOT sign modulation),
B1 (functional completeness of $\{$NOT, AND$\}$),
C1 (D-latch bistability),
D1--D2 (sequential composition).

%-----------------------------------------------------------------------
\begin{thebibliography}{99}

\bibitem{hopfield1982}
J.~J.~Hopfield,
\textit{Neural networks and physical systems with emergent collective
computational abilities},
Proc.\ Natl.\ Acad.\ Sci.\ USA \textbf{79}, 2554 (1982).

\bibitem{amit1985}
D.~J.~Amit, H.~Gutfreund, and H.~Sompolinsky,
\textit{Storing infinite numbers of patterns in a spin-glass model of neural
networks},
Phys.\ Rev.\ Lett.\ \textbf{55}, 1530 (1985).

\bibitem{krotov2016}
D.~Krotov and J.~J.~Hopfield,
\textit{Dense associative memory for pattern recognition},
Adv.\ Neural Inf.\ Process.\ Syst.\ \textbf{29} (2016).

\bibitem{krotov2020}
D.~Krotov and J.~J.~Hopfield,
\textit{Large associative memory problem in neuroscience and machine learning},
arXiv:2008.06996 (2020).

\bibitem{ramsauer2020}
H.~Ramsauer, B.~Sch\"afl, J.~Lehner, P.~Seidl, M.~Widrich, T.~Adler,
L.~Gruber, M.~Holzleitner, M.~Pavlovi\'c, G.~K.~Sandve, V.~Greiff,
D.~Kreil, M.~Kopp, G.~Klambauer, J.~Brandstetter, and S.~Hochreiter,
\textit{Hopfield networks is all you need},
arXiv:2008.02217 (2020).

\bibitem{vaswani2017}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N.~Gomez,
\L.~Kaiser, and I.~Polosukhin,
\textit{Attention is all you need},
Adv.\ Neural Inf.\ Process.\ Syst.\ \textbf{30} (2017).

\bibitem{kuramoto1984}
Y.~Kuramoto,
\textit{Chemical Oscillations, Waves, and Turbulence}
(Springer, Berlin, 1984).

\bibitem{strogatz2000}
S.~H.~Strogatz,
\textit{From Kuramoto to Crawford: exploring the onset of synchronization
in populations of coupled oscillators},
Physica D \textbf{143}, 1 (2000).

\bibitem{jaeger2001}
H.~Jaeger,
\textit{The "echo state" approach to analysing and training recurrent neural
networks},
GMD Report 148, German National Research Center for Information Technology (2001).

\bibitem{maass2002}
W.~Maass, T.~Natschl\"ager, and H.~Markram,
\textit{Real-time computing without stable states: a new framework for
neural computation based on perturbations},
Neural Comput.\ \textbf{14}, 2531 (2002).

\bibitem{mardia2009}
K.~V.~Mardia and P.~E.~Jupp,
\textit{Directional Statistics}
(Wiley, Chichester, 2009).

\bibitem{zenodo2025}
K.~Gwó\'zd\'z,
\textit{Phase Entanglement RC --- REZON oscillator network experiments},
Zenodo, \href{https://doi.org/10.5281/zenodo.18800042}{doi:10.5281/zenodo.18800042} (2025).

\bibitem{hirsch1974}
M.~W.~Hirsch and S.~Smale,
\textit{Differential Equations, Dynamical Systems, and Linear Algebra}
(Academic Press, New York, 1974).

\bibitem{aoyagi1995}
T.~Aoyagi,
\textit{Network of neural oscillators for retrieving phase information},
Phys.\ Rev.\ Lett.\ \textbf{74}, 4075 (1995).

\bibitem{tanaka1998}
T.~Tanaka and A.~C.~C.~Coolen,
\textit{Statistical mechanics of phase-coupled oscillator networks
with pattern retrieval},
J.\ Phys.\ A: Math.\ Gen.\ \textbf{31}, 7061 (1998).

\bibitem{noest1988}
A.~J.~Noest,
\textit{Phasor neural networks},
Adv.\ Neural Inf.\ Process.\ Syst.\ \textbf{1} (1988).

\bibitem{chaudhuri1993}
A.~Chaudhuri and A.~Bhattacharya,
\textit{Associative memory with complex-valued units},
Neural Netw.\ \textbf{6}, 975 (1993).

\bibitem{skardal2025}
P.~S.~Skardal and A.~Arenas,
\textit{Higher-order Kuramoto dynamics and dense associative memory},
arXiv:2507.21984 (2025).

\bibitem{optimcap2024}
J.~Y.-C.~Hu, D.~Wu, and H.~Liu,
\textit{Provably optimal memory capacity for modern Hopfield models:
Transformer-compatible dense associative memories as spherical codes},
Adv.\ Neural Inf.\ Process.\ Syst.\ \textbf{37} (NeurIPS 2024);
arXiv:2410.23126.

\bibitem{grollier2016}
J.~Grollier, D.~Querlioz, and M.~D.~Stiles,
\textit{Spintronic nanodevices for bioinspired computing},
Proc.\ IEEE \textbf{104}, 2024 (2016).

\bibitem{romera2018}
P.~Romera, P.~Talatchian, S.~Tsunegi, F.~Abreu~Araujo,
V.~Cros, P.~Bortolotti, K.~Yakushiji, A.~Fukushima,
H.~Kubota, S.~Yuasa, M.~Ernoult, D.~Vodenicarevic,
T.~Hirtzlin, N.~Locatelli, D.~Querlioz, and J.~Grollier,
\textit{Vowel recognition with four coupled spin-torque nano-oscillators},
Nature \textbf{563}, 230 (2018).

\end{thebibliography}

\end{document}
